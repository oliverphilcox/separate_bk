# Base configuration
defaults: &defaults
  # number of training epochs
  epochs: 250
  # batch size for inference
  batch_size: 1024
  # stop after "patience" epochs without improvement
  patience: 50
  # directories for output
  model_dir: 'models/fiducial'
  results_dir: 'results/fiducial'

# Dataset configuration
dataset: &dataset
  ## File containing external_dataset
  # Format: (k1, k2, k3, S(k1,k2,k3))
  datafile: 'datasets/planck_local.txt'
  
# Model configuration
model: &model
  # maximum number of terms in separable representation
  num_terms: 1
  # target accuracy for template
  threshold: 0.999
  # whether to update the weights each time we increase the number of terms or start from scratch
  update_weights: true
  # Type of symmetry
  # 0: 1/6 [ alpha(k1) beta(k2) / alpha(k3) / beta(k3) + 5 perm.]
  # 1: 1/6 [ alpha(k1) beta(k2) gamma(k3) + 5 perm. ]
  # 2: 1/3 [ alpha(k1) beta(k2) beta(k3) + 2 cyc. ]
  # 3: [ alpha(k1) alpha(k2) alpha(k3) ]
  # Type 1 is usually preferred
  symm_kind: 1
  # Whether to add a constant term to the model
  # This is rarely useful
  add_bias: false
  # Apply log transform to inputs, i.e. use exp(f(x)) instead of f(x)
  log_transform: true
  # Architecture for alpha, beta, gamma (MLP or ResMLP; MLP usually works well)
  sub_arch: 'MLP'
  # type of loss: [inner, mse, cosine]
  # inner approximates the true inner product between shapes
  # mse is the standard least squares loss
  # cosine is the cosine between shapes. It does not get the normalization correct
  loss_func: 'inner'
  # Filtering function used to weight ks
  filterfile: 'planckTE_k_filtering.npy'

# List of experiments (will be run in serial)
experiments:
  ## Here is a test example of running linear and log models with up to 3 terms (exiting when 99.9% accuracy is reached)

  max3-lin:
    <<: *defaults
    description: ""
    model_params:
      <<: *model
      num_terms: 3
      threshold: 0.999
      log_transform: false
    dataset_params:
       <<: *dataset

  max3-log:
    <<: *defaults
    description: ""
    model_params:
      <<: *model
      num_terms: 3
      threshold: 0.999
      log_transform: true
    dataset_params:
       <<: *dataset